{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "106403551_呂晟維.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wA7PNlYMN_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "clear = lambda: os.system('cls') # windows\n",
        "clear = lambda: os.system('clear') #linux"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdLtv_y8NW5t",
        "colab_type": "text"
      },
      "source": [
        "### global variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfSr-quxNN1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROW, COL = 30, 40\n",
        "N_STATES = ROW*COL   #有多少種states\n",
        "ACTIONS = ['left', 'right', 'up', 'down']     #可以做的動作\n",
        "EPSILON = 0.9   # epsilon greedy\n",
        "ALPHA = 0.1     # learning rate\n",
        "GAMMA = 0.9    # discount factor\n",
        "MAX_EPISODES = 100   # maximum episodes\n",
        "FRESH_TIME = 0.15    # fresh time for one move\n",
        "MIN_STEP = 1e8\n",
        "MIS_STEP_EPISODE = 1e5\n",
        "# np.random.seed(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duMktTpzNSjQ",
        "colab_type": "text"
      },
      "source": [
        "### 建立Q table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHwiBzZtrKg_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "3x3 的 Q table:\n",
        "```\n",
        "0 1 2\n",
        "3 4 5\n",
        "6 7 8\n",
        "```\n",
        "```\n",
        "o - -\n",
        "- - -\n",
        "- - T\n",
        "```\n",
        "3x4 的 Q table:\n",
        "```\n",
        "0 1 2 3\n",
        "4 5 6 7\n",
        "8 9 10 11\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOWOGlvDNQaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_q_table(n_states, actions): \n",
        "    table = pd.DataFrame(np.zeros((n_states, len(actions))),columns=actions,)   \n",
        "    return table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PRZBSQ2Nd__",
        "colab_type": "text"
      },
      "source": [
        "### choose action的功能"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1JyoylANcTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_action(state, q_table): \n",
        "    state_actions = q_table.iloc[state, :] #取state這一行的對應資料 (Series)\n",
        "    #act non-greedy or state-action have no value\n",
        "    if (np.random.uniform() > EPSILON) or ((state_actions == 0).all()):  \n",
        "        action_name = np.random.choice(ACTIONS) \n",
        "    else:   # act greedy\n",
        "        action_name = state_actions.idxmax()\n",
        "    return action_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y50bBLRbNiRw",
        "colab_type": "text"
      },
      "source": [
        "### 建立環境對我們行為的feedback\n",
        "1.   寶藏 reward 給超多，ex:1e8\n",
        "2.   撞牆 reward 給負超多，ex: -1e5\n",
        "3.   當機器人`上一個位置離終點的距離` 比 `這一次位置離終點的距離` 大的話，代表有朝終點走，reward 給正的；反之給負的。 (有設計reward隨距離指數遞增>好像沒實際用上) ex: 1 or -1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1ELvoPTI4fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance(S, S_):\n",
        "    '''distance = 所需步數 = 水平距離+垂直距離'''\n",
        "    x, y = S%COL, int(S/COL)\n",
        "    x_, y_ = S_%COL, int(S_/COL)\n",
        "    distance = abs(x-x_) + abs(y-y_)\n",
        "    # print('x:', x, 'y:',y)\n",
        "    # print('x_:', x_, 'y_:',y_)\n",
        "    # print('distance:', distance)\n",
        "\n",
        "    return distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIBkcO--QNP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reward(S, S_):\n",
        "    '''reward = 1/接近寶藏的距離，正分從1~0的指數遞減(變近)，距離遠負分'''\n",
        "    d  = distance(S, N_STATES-1)\n",
        "    d_ = distance(S_, N_STATES-1)\n",
        "    difference = d - d_\n",
        "    reward = 1/difference\n",
        "    return reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P0R6rRVLirv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distance(0, 1199)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ8FXjKaRHuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reward(2, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlWma7ypNgv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_env_feedback(S, A): \n",
        "    R = 0\n",
        "\n",
        "    if A == 'right':    # move right\n",
        "        if S == N_STATES - 2:   # 寶藏前一個位置\n",
        "            S_ = 'terminal'  \n",
        "            R = 1e5 # 找到才給reward\n",
        "        elif (S+1)%COL == 0:\n",
        "            # print('reach right wall')\n",
        "            S_ = S  # reach right wall\n",
        "            R = -1e5\n",
        "        else: \n",
        "            S_ = S + 1 \n",
        "            R = reward(S, S_)\n",
        "\n",
        "    if A == 'left':   # move left\n",
        "        if (S)%COL == 0:\n",
        "            # print('reach left wall')\n",
        "            S_ = S  # reach left wall\n",
        "            R = -1e5\n",
        "        else:\n",
        "            S_ = S - 1\n",
        "            R = reward(S, S_)\n",
        "\n",
        "    if A == 'up':\n",
        "        if S < COL:\n",
        "            # print('reach top wall')\n",
        "            S_ = S  # reach top wall\n",
        "            R = -1e5\n",
        "        else:\n",
        "            S_ = S - COL\n",
        "            R = reward(S, S_)\n",
        "\n",
        "    if A == 'down':\n",
        "        if (S+COL) == N_STATES - 1:\n",
        "            S_ = 'terminal'  # FIND !!!\n",
        "            R = 1e5 \n",
        "        elif S >= (ROW-1)*COL:\n",
        "            # print('reach down wall')\n",
        "            S_ = S  # reach down wall\n",
        "            R = -1e5\n",
        "        else:\n",
        "            S_ = S + COL\n",
        "            R = reward(S, S_)\n",
        "      \n",
        "    return S_, R"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLPTAt6AAaJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "S, A = 11990, 'down'\n",
        "S_, R = get_env_feedback(S, A)\n",
        "print(\"S next:\", S_, \"Reowrd:\", R)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHsZ-WAXNjqE",
        "colab_type": "text"
      },
      "source": [
        "### 更新環境"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ9WVxnANnh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_env(S, episode, step_counter):\n",
        "    # '---------T' draw our 2D environment \n",
        "    # env_list = []\n",
        "    # i = 0\n",
        "    # for c in range(ROW):\n",
        "    #     for r in range(COL):\n",
        "    #         if i == S:\n",
        "    #             env_list += 'o'\n",
        "    #         else:\n",
        "    #             env_list += '-'\n",
        "    #         i += 1\n",
        "    #     env_list += '\\n'\n",
        "    # env_list = env_list[:-2]\n",
        "    # env_list += 'T\\n'\n",
        "    \n",
        "    if S == 'terminal': \n",
        "        interaction = 'Episode %s: total_steps = %s' % (episode+1, step_counter) #回應\n",
        "        # clear_output(wait=True)\n",
        "        print('\\r', end='')\n",
        "        print('{}'.format(interaction)) \n",
        "        # time.sleep(1)                             \n",
        "        # print('\\r                                ', end='') #清空\n",
        "        # 紀錄最小總步數\n",
        "        global MIN_STEP\n",
        "        global MIS_STEP_EPISODE\n",
        "        if step_counter < MIN_STEP:\n",
        "            MIN_STEP = step_counter\n",
        "            MIS_STEP_EPISODE = episode+1\n",
        "    else:\n",
        "        if step_counter!=0 and step_counter%1000 == 0:\n",
        "        # interaction = ''.join(env_list) \n",
        "            # clear_output(wait=True)\n",
        "            print('\\r', end='')\n",
        "            print('\\r', end='')\n",
        "            print(f'Episode *{episode+1}: current_step = {step_counter}', end='')\n",
        "        # print('{}'.format(interaction), end='')\n",
        "        # time.sleep(FRESH_TIME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Z0Ghb6GHj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "update_env(S=4, episode=1, step_counter=500)\n",
        "update_env(S=4, episode=2, step_counter=1000)\n",
        "update_env(S='terminal', episode=3, step_counter=1500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrifWbxeNp-Y",
        "colab_type": "text"
      },
      "source": [
        "### 建立reinforcement learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qpq4a0bNtVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rl():\n",
        "    q_table = build_q_table(N_STATES, ACTIONS) #建立 Q table\n",
        "    for episode in range(MAX_EPISODES): #從第一個回合玩到最後一個回合\n",
        "        step_counter = 0\n",
        "        S = 0 #初始情況，探索者放到左邊\n",
        "        is_terminated = False \n",
        "        # EPSILON Greedy\n",
        "        update_env(S, episode, step_counter) #更新環境\n",
        "        while not is_terminated: #回合沒有結束\n",
        "\n",
        "            A = choose_action(S, q_table) \n",
        "            S_, R = get_env_feedback(S, A)  \n",
        "            q_predict = q_table.loc[S, A] #估計值 Single label for row and column > loc[index, col]\n",
        "            if S_ != 'terminal': #回合還沒結束\n",
        "                q_target = R + GAMMA * q_table.iloc[S_, :].max()   #真實值 \n",
        "            else:\n",
        "                q_target = R    \n",
        "                is_terminated = True    # 結束這一回合\n",
        "                \n",
        "            q_table.loc[S, A] += ALPHA * (q_target - q_predict)  # update\n",
        "            S = S_  # move to next state\n",
        "\n",
        "            update_env(S, episode, step_counter+1)\n",
        "            step_counter += 1\n",
        "    return q_table, step_counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G9H_LlYNsid",
        "colab_type": "text"
      },
      "source": [
        "### Execute Program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRzSSy6YNxMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3da9c710-7506-410a-9a7d-97a14adbb6e1"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    q_table, step = rl()\n",
        "    # clear_output(wait=True)\n",
        "    print()\n",
        "    print('minina step:', MIN_STEP, '@ episode',MIS_STEP_EPISODE)\n",
        "    print('\\nQ-table:\\n')\n",
        "    print(q_table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpisode 1: total_steps = 223\n",
            "Episode 2: total_steps = 215\n",
            "Episode 3: total_steps = 152\n",
            "Episode 4: total_steps = 92\n",
            "Episode 5: total_steps = 92\n",
            "Episode 6: total_steps = 79\n",
            "Episode 7: total_steps = 78\n",
            "Episode 8: total_steps = 96\n",
            "Episode 9: total_steps = 100\n",
            "Episode 10: total_steps = 105\n",
            "Episode 11: total_steps = 82\n",
            "Episode 12: total_steps = 83\n",
            "Episode 13: total_steps = 83\n",
            "Episode 14: total_steps = 81\n",
            "Episode 15: total_steps = 68\n",
            "Episode 16: total_steps = 80\n",
            "Episode 17: total_steps = 77\n",
            "Episode 18: total_steps = 76\n",
            "Episode 19: total_steps = 87\n",
            "Episode 20: total_steps = 74\n",
            "Episode 21: total_steps = 96\n",
            "Episode 22: total_steps = 75\n",
            "Episode 23: total_steps = 86\n",
            "Episode 24: total_steps = 75\n",
            "Episode 25: total_steps = 78\n",
            "Episode 26: total_steps = 76\n",
            "Episode 27: total_steps = 81\n",
            "Episode 28: total_steps = 76\n",
            "Episode 29: total_steps = 78\n",
            "Episode 30: total_steps = 74\n",
            "Episode 31: total_steps = 74\n",
            "Episode 32: total_steps = 74\n",
            "Episode 33: total_steps = 74\n",
            "Episode 34: total_steps = 78\n",
            "Episode 35: total_steps = 74\n",
            "Episode 36: total_steps = 72\n",
            "Episode 37: total_steps = 79\n",
            "Episode 38: total_steps = 85\n",
            "Episode 39: total_steps = 76\n",
            "Episode 40: total_steps = 76\n",
            "Episode 41: total_steps = 70\n",
            "Episode 42: total_steps = 94\n",
            "Episode 43: total_steps = 76\n",
            "Episode 44: total_steps = 72\n",
            "Episode 45: total_steps = 68\n",
            "Episode 46: total_steps = 75\n",
            "Episode 47: total_steps = 78\n",
            "Episode 48: total_steps = 77\n",
            "Episode 49: total_steps = 79\n",
            "Episode 50: total_steps = 73\n",
            "Episode 51: total_steps = 82\n",
            "Episode 52: total_steps = 88\n",
            "Episode 53: total_steps = 81\n",
            "Episode 54: total_steps = 80\n",
            "Episode 55: total_steps = 72\n",
            "Episode 56: total_steps = 70\n",
            "Episode 57: total_steps = 70\n",
            "Episode 58: total_steps = 70\n",
            "Episode 59: total_steps = 77\n",
            "Episode 60: total_steps = 74\n",
            "Episode 61: total_steps = 108\n",
            "Episode 62: total_steps = 76\n",
            "Episode 63: total_steps = 84\n",
            "Episode 64: total_steps = 87\n",
            "Episode 65: total_steps = 75\n",
            "Episode 66: total_steps = 70\n",
            "Episode 67: total_steps = 76\n",
            "Episode 68: total_steps = 74\n",
            "Episode 69: total_steps = 76\n",
            "Episode 70: total_steps = 73\n",
            "Episode 71: total_steps = 76\n",
            "Episode 72: total_steps = 75\n",
            "Episode 73: total_steps = 78\n",
            "Episode 74: total_steps = 74\n",
            "Episode 75: total_steps = 74\n",
            "Episode 76: total_steps = 75\n",
            "Episode 77: total_steps = 76\n",
            "Episode 78: total_steps = 70\n",
            "Episode 79: total_steps = 80\n",
            "Episode 80: total_steps = 68\n",
            "Episode 81: total_steps = 78\n",
            "Episode 82: total_steps = 73\n",
            "Episode 83: total_steps = 70\n",
            "Episode 84: total_steps = 81\n",
            "Episode 85: total_steps = 72\n",
            "Episode 86: total_steps = 80\n",
            "Episode 87: total_steps = 82\n",
            "Episode 88: total_steps = 77\n",
            "Episode 89: total_steps = 74\n",
            "Episode 90: total_steps = 68\n",
            "Episode 91: total_steps = 82\n",
            "Episode 92: total_steps = 79\n",
            "Episode 93: total_steps = 79\n",
            "Episode 94: total_steps = 78\n",
            "Episode 95: total_steps = 70\n",
            "Episode 96: total_steps = 73\n",
            "Episode 97: total_steps = 87\n",
            "Episode 98: total_steps = 73\n",
            "Episode 99: total_steps = 74\n",
            "Episode 100: total_steps = 73\n",
            "\n",
            "minina step: 68 @ episode 15\n",
            "\n",
            "Q-table:\n",
            "\n",
            "              left         right            up          down\n",
            "0    -34388.952786      0.549369 -52168.743746      6.298739\n",
            "1         0.000000      0.100000      0.000000      1.864214\n",
            "2         0.000000      0.000000      0.000000      0.100000\n",
            "3         0.000000      0.000000      0.000000      0.000000\n",
            "4         0.000000      0.000000      0.000000      0.000000\n",
            "...            ...           ...           ...           ...\n",
            "1195     -0.091000      7.661886      0.000000      0.000000\n",
            "1196     -0.091000    300.035712      0.000000 -18999.991000\n",
            "1197      0.000000   4707.468559      0.000000  -9999.975610\n",
            "1198     -0.164800  34390.000000      0.000000      0.000000\n",
            "1199      0.000000      0.000000      0.000000      0.000000\n",
            "\n",
            "[1200 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRMjIrCn5_ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q_table.to_csv('q_table.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}